"""
ðŸ“Š Advanced Monitoring System

Real-time monitoring and observability for federated learning:
- Multi-dimensional metrics collection
- Predictive anomaly detection
- Performance analytics dashboard
- Privacy-preserving telemetry
- Automated alerting and incident response
"""

import asyncio
import logging
import time
from collections import defaultdict, deque
from dataclasses import dataclass, asdict
from enum import Enum
from typing import Dict, List, Optional, Callable, Any, Tuple, Union
import json
import statistics
from pathlib import Path
import threading
import queue

import numpy as np

logger = logging.getLogger(__name__)


class MetricType(Enum):
    """Types of metrics to collect."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    PRIVACY = "privacy"
    QUANTUM = "quantum"


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


@dataclass
class MetricPoint:
    """A single metric data point."""
    name: str
    value: Union[float, int]
    timestamp: float
    labels: Dict[str, str]
    metric_type: MetricType
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return asdict(self)


@dataclass
class Alert:
    """An alert generated by the monitoring system."""
    alert_id: str
    name: str
    severity: AlertSeverity
    message: str
    timestamp: float
    labels: Dict[str, str]
    resolved: bool = False
    resolution_time: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return asdict(self)


class MetricsCollector:
    """Advanced metrics collector with buffering and aggregation."""
    
    def __init__(self, buffer_size: int = 10000):
        self.buffer_size = buffer_size
        self.metrics_buffer = deque(maxlen=buffer_size)
        self.metric_registry = {}
        self.collectors = {}
        self.lock = threading.RLock()
        
    def register_metric(self, name: str, metric_type: MetricType, 
                       help_text: str = "", labels: List[str] = None) -> None:
        """Register a new metric."""
        with self.lock:
            self.metric_registry[name] = {
                "type": metric_type,
                "help": help_text,
                "labels": labels or [],
                "created": time.time()
            }
            
        logger.debug(f"ðŸ“Š Registered metric: {name} ({metric_type.value})")
        
    def record_metric(self, name: str, value: Union[float, int], 
                     labels: Dict[str, str] = None) -> None:
        """Record a metric value."""
        if name not in self.metric_registry:
            logger.warning(f"Unknown metric: {name}")
            return
            
        metric_point = MetricPoint(
            name=name,
            value=value,
            timestamp=time.time(),
            labels=labels or {},
            metric_type=self.metric_registry[name]["type"]
        )
        
        with self.lock:
            self.metrics_buffer.append(metric_point)
            
    def increment(self, name: str, amount: float = 1.0, 
                  labels: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        self.record_metric(name, amount, labels)
        
    def set_gauge(self, name: str, value: Union[float, int],
                  labels: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        self.record_metric(name, value, labels)
        
    def observe_histogram(self, name: str, value: float,
                         labels: Dict[str, str] = None) -> None:
        """Observe a value for histogram metric."""
        self.record_metric(name, value, labels)
        
    def get_recent_metrics(self, duration: float = 60.0) -> List[MetricPoint]:
        """Get metrics from the last duration seconds."""
        cutoff_time = time.time() - duration
        
        with self.lock:
            return [m for m in self.metrics_buffer if m.timestamp >= cutoff_time]
            
    def get_metric_summary(self, name: str, duration: float = 300.0) -> Dict[str, Any]:
        """Get statistical summary for a metric."""
        recent_metrics = self.get_recent_metrics(duration)
        values = [m.value for m in recent_metrics if m.name == name]
        
        if not values:
            return {"count": 0}
            
        return {
            "count": len(values),
            "sum": sum(values),
            "mean": statistics.mean(values),
            "median": statistics.median(values),
            "min": min(values),
            "max": max(values),
            "std": statistics.stdev(values) if len(values) > 1 else 0.0
        }


class AnomalyDetector:
    """Statistical anomaly detector for metrics."""
    
    def __init__(self, window_size: int = 100, threshold: float = 3.0):
        self.window_size = window_size
        self.threshold = threshold
        self.metric_windows = defaultdict(lambda: deque(maxlen=window_size))
        self.baselines = {}
        
    def update_baseline(self, name: str, value: float) -> None:
        """Update baseline statistics for a metric."""
        self.metric_windows[name].append(value)
        
        if len(self.metric_windows[name]) >= 10:  # Minimum samples for baseline
            values = list(self.metric_windows[name])
            self.baselines[name] = {
                "mean": statistics.mean(values),
                "std": statistics.stdev(values) if len(values) > 1 else 0.1,
                "updated": time.time()
            }
            
    def detect_anomaly(self, name: str, value: float) -> Tuple[bool, float]:
        """Detect if a value is anomalous."""
        if name not in self.baselines:
            self.update_baseline(name, value)
            return False, 0.0
            
        baseline = self.baselines[name]
        
        if baseline["std"] == 0:
            return False, 0.0
            
        z_score = abs(value - baseline["mean"]) / baseline["std"]
        is_anomaly = z_score > self.threshold
        
        # Update baseline with new value
        self.update_baseline(name, value)
        
        return is_anomaly, z_score


class AlertManager:
    """Manages alerts and notifications."""
    
    def __init__(self):
        self.active_alerts = {}
        self.alert_history = deque(maxlen=1000)
        self.alert_rules = {}
        self.notification_channels = []
        
    def add_alert_rule(self, name: str, condition: Callable[[Dict[str, Any]], bool],
                      severity: AlertSeverity, message_template: str) -> None:
        """Add an alert rule."""
        self.alert_rules[name] = {
            "condition": condition,
            "severity": severity,
            "message_template": message_template,
            "created": time.time()
        }
        
        logger.info(f"ðŸ”” Added alert rule: {name}")
        
    async def evaluate_alerts(self, metrics: Dict[str, Any]) -> List[Alert]:
        """Evaluate alert rules against current metrics."""
        new_alerts = []
        
        for rule_name, rule in self.alert_rules.items():
            try:
                if rule["condition"](metrics):
                    # Create alert
                    alert = Alert(
                        alert_id=f"{rule_name}_{int(time.time())}",
                        name=rule_name,
                        severity=rule["severity"],
                        message=rule["message_template"].format(**metrics),
                        timestamp=time.time(),
                        labels={"rule": rule_name}
                    )
                    
                    # Check if similar alert already active
                    alert_key = f"{rule_name}_{rule['severity'].value}"
                    if alert_key not in self.active_alerts:
                        self.active_alerts[alert_key] = alert
                        self.alert_history.append(alert)
                        new_alerts.append(alert)
                        
                        await self._send_alert_notification(alert)
                        
            except Exception as e:
                logger.error(f"Error evaluating alert rule {rule_name}: {e}")
                
        return new_alerts
        
    async def resolve_alert(self, alert_id: str) -> bool:
        """Resolve an active alert."""
        for key, alert in self.active_alerts.items():
            if alert.alert_id == alert_id:
                alert.resolved = True
                alert.resolution_time = time.time()
                del self.active_alerts[key]
                
                logger.info(f"âœ… Resolved alert: {alert.name}")
                return True
                
        return False
        
    async def _send_alert_notification(self, alert: Alert) -> None:
        """Send alert notification through configured channels."""
        message = f"ðŸš¨ {alert.severity.value.upper()}: {alert.message}"
        
        # Log alert
        if alert.severity == AlertSeverity.EMERGENCY:
            logger.critical(message)
        elif alert.severity == AlertSeverity.CRITICAL:
            logger.error(message)
        elif alert.severity == AlertSeverity.WARNING:
            logger.warning(message)
        else:
            logger.info(message)
            
        # Send through notification channels
        for channel in self.notification_channels:
            try:
                await channel.send_notification(alert)
            except Exception as e:
                logger.error(f"Failed to send alert through {channel}: {e}")
                
    def get_active_alerts(self) -> List[Alert]:
        """Get list of active alerts."""
        return list(self.active_alerts.values())
        
    def get_alert_summary(self) -> Dict[str, Any]:
        """Get alert summary statistics."""
        recent_alerts = [a for a in self.alert_history if time.time() - a.timestamp < 3600]  # Last hour
        
        severity_counts = defaultdict(int)
        for alert in recent_alerts:
            severity_counts[alert.severity.value] += 1
            
        return {
            "active_alerts": len(self.active_alerts),
            "alerts_last_hour": len(recent_alerts),
            "severity_distribution": dict(severity_counts)
        }


class PrivacyPreservingTelemetry:
    """Privacy-preserving telemetry collection."""
    
    def __init__(self, epsilon: float = 1.0, delta: float = 1e-5):
        self.epsilon = epsilon
        self.delta = delta
        self.noise_scale = 1.0 / epsilon  # Simplified noise calculation
        
    def collect_private_metric(self, metric_name: str, true_value: float,
                              sensitivity: float = 1.0) -> float:
        """Collect metric with differential privacy."""
        # Add Laplace noise for differential privacy
        noise = np.random.laplace(0, sensitivity / self.epsilon)
        private_value = true_value + noise
        
        logger.debug(f"ðŸ”’ Private metric {metric_name}: {true_value} -> {private_value:.3f}")
        return private_value
        
    def aggregate_private_metrics(self, values: List[float], 
                                 sensitivity: float = 1.0) -> Dict[str, float]:
        """Aggregate metrics with privacy preservation."""
        if not values:
            return {}
            
        # Private statistics
        private_sum = sum(values) + np.random.laplace(0, sensitivity / self.epsilon)
        private_count = len(values) + np.random.laplace(0, 1.0 / self.epsilon)
        private_mean = private_sum / max(private_count, 1)
        
        return {
            "private_sum": private_sum,
            "private_count": max(private_count, 0),  # Ensure non-negative
            "private_mean": private_mean
        }


class FederatedMonitoringDashboard:
    """Advanced monitoring dashboard for federated learning."""
    
    def __init__(self, privacy_budget: float = 2.0):
        self.metrics_collector = MetricsCollector()
        self.anomaly_detector = AnomalyDetector()
        self.alert_manager = AlertManager()
        self.privacy_telemetry = PrivacyPreservingTelemetry(epsilon=privacy_budget)
        
        # Initialize standard metrics
        self._register_standard_metrics()
        
        # Setup alert rules
        self._setup_standard_alerts()
        
        # Monitoring tasks
        self.monitoring_tasks = []
        self.running = False
        
    def _register_standard_metrics(self) -> None:
        """Register standard federated learning metrics."""
        standard_metrics = [
            ("fl_clients_active", MetricType.GAUGE, "Number of active clients"),
            ("fl_rounds_completed", MetricType.COUNTER, "Completed training rounds"),
            ("fl_model_accuracy", MetricType.GAUGE, "Global model accuracy"),
            ("fl_privacy_epsilon", MetricType.GAUGE, "Privacy epsilon spent"),
            ("fl_aggregation_latency", MetricType.HISTOGRAM, "Model aggregation latency"),
            ("fl_byzantine_detected", MetricType.COUNTER, "Byzantine clients detected"),
            ("fl_quantum_coherence", MetricType.GAUGE, "Quantum coherence factor"),
            ("system_cpu_usage", MetricType.GAUGE, "CPU usage percentage"),
            ("system_memory_usage", MetricType.GAUGE, "Memory usage percentage"),
            ("system_network_latency", MetricType.HISTOGRAM, "Network latency"),
        ]
        
        for name, metric_type, help_text in standard_metrics:
            self.metrics_collector.register_metric(name, metric_type, help_text)
            
    def _setup_standard_alerts(self) -> None:
        """Setup standard alert rules."""
        # High CPU usage
        self.alert_manager.add_alert_rule(
            "high_cpu_usage",
            lambda m: m.get("system_cpu_usage", 0) > 90,
            AlertSeverity.WARNING,
            "High CPU usage detected: {system_cpu_usage:.1f}%"
        )
        
        # Low model accuracy
        self.alert_manager.add_alert_rule(
            "low_model_accuracy",
            lambda m: m.get("fl_model_accuracy", 1.0) < 0.7,
            AlertSeverity.CRITICAL,
            "Model accuracy dropped below threshold: {fl_model_accuracy:.3f}"
        )
        
        # Privacy budget exhausted
        self.alert_manager.add_alert_rule(
            "privacy_budget_exhausted",
            lambda m: m.get("fl_privacy_epsilon", 0) > 8.0,
            AlertSeverity.EMERGENCY,
            "Privacy budget nearly exhausted: Îµ={fl_privacy_epsilon:.2f}"
        )
        
        # Few active clients
        self.alert_manager.add_alert_rule(
            "few_active_clients",
            lambda m: m.get("fl_clients_active", 0) < 5,
            AlertSeverity.WARNING,
            "Low number of active clients: {fl_clients_active}"
        )
        
        # Byzantine clients detected
        self.alert_manager.add_alert_rule(
            "byzantine_activity",
            lambda m: m.get("fl_byzantine_detected", 0) > 2,
            AlertSeverity.CRITICAL,
            "Multiple Byzantine clients detected: {fl_byzantine_detected}"
        )
        
    async def start_monitoring(self) -> None:
        """Start the monitoring system."""
        logger.info("ðŸ“Š Starting federated monitoring dashboard")
        self.running = True
        
        # Start monitoring tasks
        self.monitoring_tasks = [
            asyncio.create_task(self._collect_system_metrics()),
            asyncio.create_task(self._detect_anomalies()),
            asyncio.create_task(self._evaluate_alerts()),
            asyncio.create_task(self._generate_reports())
        ]
        
        try:
            await asyncio.gather(*self.monitoring_tasks)
        except asyncio.CancelledError:
            logger.info("ðŸ›‘ Monitoring stopped")
            
    async def _collect_system_metrics(self) -> None:
        """Continuously collect system metrics."""
        while self.running:
            # Simulate system metrics collection
            cpu_usage = np.random.uniform(20, 95)
            memory_usage = np.random.uniform(30, 85)
            network_latency = np.random.exponential(50)  # Exponential distribution for latency
            
            self.metrics_collector.set_gauge("system_cpu_usage", cpu_usage)
            self.metrics_collector.set_gauge("system_memory_usage", memory_usage)
            self.metrics_collector.observe_histogram("system_network_latency", network_latency)
            
            # Federated learning specific metrics
            active_clients = np.random.poisson(15)  # Poisson distribution for client count
            model_accuracy = max(0.5, min(1.0, 0.85 + np.random.normal(0, 0.05)))
            privacy_epsilon = np.random.uniform(0.5, 6.0)
            
            self.metrics_collector.set_gauge("fl_clients_active", active_clients)
            self.metrics_collector.set_gauge("fl_model_accuracy", model_accuracy)
            self.metrics_collector.set_gauge("fl_privacy_epsilon", privacy_epsilon)
            
            # Quantum metrics
            quantum_coherence = max(0.1, min(1.0, 0.8 + np.random.normal(0, 0.1)))
            self.metrics_collector.set_gauge("fl_quantum_coherence", quantum_coherence)
            
            await asyncio.sleep(10)  # Collect every 10 seconds
            
    async def _detect_anomalies(self) -> None:
        """Detect anomalies in metrics."""
        while self.running:
            recent_metrics = self.metrics_collector.get_recent_metrics(60)
            
            # Group metrics by name
            metric_groups = defaultdict(list)
            for metric in recent_metrics:
                metric_groups[metric.name].append(metric.value)
                
            # Check each metric group for anomalies
            for metric_name, values in metric_groups.items():
                if values:
                    latest_value = values[-1]
                    is_anomaly, z_score = self.anomaly_detector.detect_anomaly(metric_name, latest_value)
                    
                    if is_anomaly:
                        logger.warning(f"ðŸ” Anomaly detected in {metric_name}: {latest_value:.3f} (z-score: {z_score:.2f})")
                        
            await asyncio.sleep(30)  # Check every 30 seconds
            
    async def _evaluate_alerts(self) -> None:
        """Evaluate alert rules."""
        while self.running:
            # Get current metric values
            current_metrics = {}
            for metric_name in ["system_cpu_usage", "system_memory_usage", "fl_clients_active", 
                               "fl_model_accuracy", "fl_privacy_epsilon", "fl_byzantine_detected"]:
                recent = self.metrics_collector.get_recent_metrics(60)
                matching = [m.value for m in recent if m.name == metric_name]
                if matching:
                    current_metrics[metric_name] = matching[-1]  # Most recent value
                    
            # Evaluate alerts
            new_alerts = await self.alert_manager.evaluate_alerts(current_metrics)
            
            if new_alerts:
                logger.info(f"ðŸ”” Generated {len(new_alerts)} new alerts")
                
            await asyncio.sleep(20)  # Evaluate every 20 seconds
            
    async def _generate_reports(self) -> None:
        """Generate periodic monitoring reports."""
        while self.running:
            report = self.get_monitoring_report()
            
            # Save report to file
            report_file = Path(f"monitoring_report_{int(time.time())}.json")
            with open(report_file, 'w') as f:
                json.dump(report, f, indent=2)
                
            logger.info(f"ðŸ“‹ Generated monitoring report: {report_file}")
            
            await asyncio.sleep(300)  # Generate every 5 minutes
            
    def get_monitoring_report(self) -> Dict[str, Any]:
        """Generate comprehensive monitoring report."""
        # Get metric summaries
        metric_summaries = {}
        for metric_name in self.metrics_collector.metric_registry.keys():
            metric_summaries[metric_name] = self.metrics_collector.get_metric_summary(metric_name)
            
        # Get alert summary
        alert_summary = self.alert_manager.get_alert_summary()
        
        return {
            "timestamp": time.time(),
            "system_status": "operational" if len(self.alert_manager.active_alerts) == 0 else "degraded",
            "metrics": metric_summaries,
            "alerts": alert_summary,
            "active_alerts": [alert.to_dict() for alert in self.alert_manager.get_active_alerts()],
            "privacy_telemetry": {
                "epsilon_budget": self.privacy_telemetry.epsilon,
                "delta": self.privacy_telemetry.delta
            }
        }
        
    async def stop_monitoring(self) -> None:
        """Stop the monitoring system."""
        logger.info("ðŸ”Œ Stopping monitoring dashboard")
        self.running = False
        
        for task in self.monitoring_tasks:
            task.cancel()
            
        await asyncio.gather(*self.monitoring_tasks, return_exceptions=True)
        
    # Convenience methods for external use
    def record_training_round(self, accuracy: float, epsilon_spent: float, 
                            participating_clients: int) -> None:
        """Record metrics for a training round."""
        self.metrics_collector.increment("fl_rounds_completed")
        self.metrics_collector.set_gauge("fl_model_accuracy", accuracy)
        self.metrics_collector.set_gauge("fl_privacy_epsilon", epsilon_spent)
        self.metrics_collector.set_gauge("fl_clients_active", participating_clients)
        
    def record_aggregation_latency(self, latency_ms: float) -> None:
        """Record model aggregation latency."""
        self.metrics_collector.observe_histogram("fl_aggregation_latency", latency_ms)
        
    def report_byzantine_detection(self, client_id: str) -> None:
        """Report Byzantine client detection."""
        self.metrics_collector.increment("fl_byzantine_detected", 
                                        labels={"client_id": client_id})


# Utility function to create monitoring dashboard
def create_monitoring_dashboard(privacy_budget: float = 2.0) -> FederatedMonitoringDashboard:
    """Create a federated monitoring dashboard."""
    return FederatedMonitoringDashboard(privacy_budget=privacy_budget)


# Demo function
async def demo_monitoring_system():
    """Demonstrate the monitoring system."""
    print("ðŸ“Š Advanced Monitoring System Demo")
    print("===================================")
    
    # Create monitoring dashboard
    dashboard = create_monitoring_dashboard(privacy_budget=2.0)
    
    # Start monitoring for 2 minutes
    monitoring_task = asyncio.create_task(dashboard.start_monitoring())
    
    # Simulate some federated learning events
    for round_num in range(5):
        accuracy = 0.75 + (round_num * 0.03) + np.random.normal(0, 0.01)
        epsilon_spent = round_num * 0.5 + np.random.uniform(0, 0.2)
        clients = 12 + np.random.poisson(3)
        
        dashboard.record_training_round(accuracy, epsilon_spent, clients)
        dashboard.record_aggregation_latency(np.random.exponential(100))
        
        if round_num == 3:  # Simulate Byzantine detection
            dashboard.report_byzantine_detection("malicious_client_42")
            
        await asyncio.sleep(15)
        
    # Get final report
    report = dashboard.get_monitoring_report()
    print("\nðŸ“‹ Final Monitoring Report:")
    print(json.dumps(report, indent=2))
    
    # Stop monitoring
    await dashboard.stop_monitoring()
    monitoring_task.cancel()
    
    print("\nâœ… Monitoring demo completed")


if __name__ == "__main__":
    asyncio.run(demo_monitoring_system())