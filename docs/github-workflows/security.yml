name: Security Scanning

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly security scan on Sundays at 03:00 UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Type of security scan'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - dependencies
        - code
        - secrets

env:
  PYTHON_VERSION: "3.10"

jobs:
  # Dependency vulnerability scanning
  dependency-scan:
    name: Dependency Vulnerability Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: ${{ github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == 'dependencies' || github.event.inputs.scan_type == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install pip-audit
    
    - name: Run Safety check
      run: |
        safety check --json --output safety-report.json || true
        safety check --short-report || true
    
    - name: Run pip-audit
      run: |
        pip-audit --format=json --output=pip-audit-report.json || true
        pip-audit --format=cyclonedx-json --output=sbom.json || true
    
    - name: Generate dependency tree
      run: |
        pip install pipdeptree
        pipdeptree --json > dependency-tree.json
    
    - name: Upload dependency reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: dependency-security-reports
        path: |
          safety-report.json
          pip-audit-report.json
          sbom.json
          dependency-tree.json
        retention-days: 90

  # Static code security analysis
  code-security:
    name: Static Code Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: ${{ github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == 'code' || github.event.inputs.scan_type == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit[toml] semgrep
    
    - name: Run Bandit security scan
      run: |
        bandit -r src/ \
          -f json \
          -o bandit-security-report.json \
          --severity-level medium \
          --confidence-level medium || true
        
        bandit -r src/ \
          -f txt \
          --severity-level high \
          --confidence-level high || true
    
    - name: Run Semgrep security scan
      run: |
        semgrep --config=auto \
          --json \
          --output=semgrep-report.json \
          src/ || true
    
    - name: Privacy-specific security checks
      run: |
        # Check for potential privacy leaks in ML code
        bandit -r src/ \
          -f json \
          -o privacy-bandit-report.json \
          --include B105,B106,B107,B108,B110,B112,B201,B301,B302,B303,B304,B305,B306,B307,B308,B309,B310,B311,B312,B313,B314,B315,B316,B317,B318,B319,B320,B321,B322,B323,B324,B325,B501,B502,B503,B504,B505,B506,B507,B601,B602,B603,B604,B605,B606,B607,B608,B609,B610,B611 || true
    
    - name: Upload code security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: code-security-reports
        path: |
          bandit-security-report.json
          semgrep-report.json
          privacy-bandit-report.json
        retention-days: 90

  # Secret scanning
  secret-scan:
    name: Secret Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: ${{ github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == 'secrets' || github.event.inputs.scan_type == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for secret scanning
    
    - name: Run TruffleHog secret scan
      uses: trufflesecurity/trufflehog@main
      with:
        base: main
        head: HEAD
        path: ./
        extra_args: --json --only-verified > trufflehog-report.json || true
    
    - name: Install gitleaks
      run: |
        wget -O gitleaks.tar.gz https://github.com/gitleaks/gitleaks/releases/download/v8.18.0/gitleaks_8.18.0_linux_x64.tar.gz
        tar -xzf gitleaks.tar.gz
        chmod +x gitleaks
    
    - name: Run Gitleaks secret scan
      run: |
        ./gitleaks detect \
          --source . \
          --report-path gitleaks-report.json \
          --report-format json \
          --verbose || true
    
    - name: Upload secret scan reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: secret-scan-reports
        path: |
          trufflehog-report.json
          gitleaks-report.json
        retention-days: 90

  # Container security scanning
  container-security:
    name: Container Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: ${{ github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image for scanning
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: dp-federated-lora:security-scan
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Run Trivy container scan
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'dp-federated-lora:security-scan'
        format: 'json'
        output: 'trivy-container-report.json'
    
    - name: Run Trivy filesystem scan
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'json'
        output: 'trivy-filesystem-report.json'
    
    - name: Upload container security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: container-security-reports
        path: |
          trivy-container-report.json
          trivy-filesystem-report.json
        retention-days: 90

  # Privacy compliance checks
  privacy-compliance:
    name: Privacy Compliance Checks
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: ${{ github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Check for privacy compliance patterns
      run: |
        # Custom privacy compliance checks for ML/DP context
        python -c "
        import json
        import os
        import re
        from pathlib import Path
        
        privacy_patterns = {
            'personal_data_patterns': [
                r'(?i)(email|phone|address|ssn|social.*security)',
                r'(?i)(name|firstname|lastname|fullname)',
                r'(?i)(birthday|birthdate|age)',
                r'(?i)(gender|race|ethnicity)',
                r'(?i)(medical|health|diagnosis)',
                r'(?i)(financial|income|salary|credit)'
            ],
            'logging_patterns': [
                r'print\s*\([^)]*(?:user|personal|private|sensitive)',
                r'log\w*\.[^(]*\([^)]*(?:user|personal|private|sensitive)',
                r'logger\.[^(]*\([^)]*(?:user|personal|private|sensitive)'
            ],
            'model_patterns': [
                r'(?i)model\.save.*user',
                r'(?i)torch\.save.*user',
                r'(?i)pickle\.(dump|save).*user'
            ]
        }
        
        violations = []
        
        for root, dirs, files in os.walk('src/'):
            for file in files:
                if file.endswith('.py'):
                    filepath = os.path.join(root, file)
                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        
                    for category, patterns in privacy_patterns.items():
                        for pattern in patterns:
                            matches = re.finditer(pattern, content, re.MULTILINE)
                            for match in matches:
                                line_num = content[:match.start()].count('\n') + 1
                                violations.append({
                                    'file': filepath,
                                    'line': line_num,
                                    'category': category,
                                    'pattern': pattern,
                                    'match': match.group()
                                })
        
        with open('privacy-compliance-report.json', 'w') as f:
            json.dump({
                'total_violations': len(violations),
                'violations_by_category': {
                    category: len([v for v in violations if v['category'] == category])
                    for category in privacy_patterns.keys()
                },
                'violations': violations
            }, f, indent=2)
        
        print(f'Privacy compliance scan complete. Found {len(violations)} potential issues.')
        "
    
    - name: Run DP-specific checks
      run: |
        python -c "
        import json
        import ast
        import os
        from pathlib import Path
        
        dp_checks = []
        
        for root, dirs, files in os.walk('src/'):
            for file in files:
                if file.endswith('.py'):
                    filepath = os.path.join(root, file)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            tree = ast.parse(f.read())
                        
                        # Check for proper epsilon usage
                        for node in ast.walk(tree):
                            if isinstance(node, ast.Name) and 'epsilon' in node.id.lower():
                                dp_checks.append({
                                    'file': filepath,
                                    'type': 'epsilon_usage',
                                    'line': getattr(node, 'lineno', 'unknown'),
                                    'variable': node.id
                                })
                            
                            # Check for noise addition
                            if isinstance(node, ast.Call) and hasattr(node.func, 'attr'):
                                if 'noise' in node.func.attr.lower() or 'gaussian' in node.func.attr.lower():
                                    dp_checks.append({
                                        'file': filepath,
                                        'type': 'noise_mechanism',
                                        'line': getattr(node, 'lineno', 'unknown'),
                                        'function': node.func.attr
                                    })
                    except Exception as e:
                        continue
        
        with open('dp-compliance-report.json', 'w') as f:
            json.dump({
                'total_dp_elements': len(dp_checks),
                'dp_elements': dp_checks
            }, f, indent=2)
        
        print(f'DP compliance scan complete. Found {len(dp_checks)} DP-related elements.')
        "
    
    - name: Upload privacy compliance reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: privacy-compliance-reports
        path: |
          privacy-compliance-report.json
          dp-compliance-report.json
        retention-days: 90

  # Security report summary
  security-summary:
    name: Security Report Summary
    runs-on: ubuntu-latest
    needs: [dependency-scan, code-security, secret-scan, container-security, privacy-compliance]
    if: always()
    
    steps:
    - name: Download all security reports
      uses: actions/download-artifact@v3
    
    - name: Generate security summary
      run: |
        python -c "
        import json
        import os
        from pathlib import Path
        
        summary = {
            'scan_timestamp': '$(date -u +"%Y-%m-%dT%H:%M:%SZ")',
            'repository': '${{ github.repository }}',
            'commit': '${{ github.sha }}',
            'branch': '${{ github.ref_name }}',
            'reports_found': [],
            'total_issues': 0,
            'high_severity_issues': 0,
            'critical_issues': 0
        }
        
        for root, dirs, files in os.walk('.'):
            for file in files:
                if file.endswith('-report.json'):
                    filepath = os.path.join(root, file)
                    summary['reports_found'].append(file)
                    
                    try:
                        with open(filepath, 'r') as f:
                            report_data = json.load(f)
                        
                        # Basic counting logic for different report types
                        if 'bandit' in file:
                            if 'results' in report_data:
                                summary['total_issues'] += len(report_data['results'])
                                summary['high_severity_issues'] += len([
                                    r for r in report_data['results'] 
                                    if r.get('issue_severity', '').lower() == 'high'
                                ])
                        elif 'safety' in file:
                            if isinstance(report_data, list):
                                summary['total_issues'] += len(report_data)
                        elif 'trivy' in file:
                            if 'Results' in report_data:
                                for result in report_data['Results']:
                                    if 'Vulnerabilities' in result:
                                        summary['total_issues'] += len(result['Vulnerabilities'])
                                        summary['critical_issues'] += len([
                                            v for v in result['Vulnerabilities']
                                            if v.get('Severity', '').upper() == 'CRITICAL'
                                        ])
                    except Exception as e:
                        print(f'Error processing {file}: {e}')
        
        with open('security-summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        print('Security Summary:')
        print(f'  Total Issues Found: {summary[\"total_issues\"]}')
        print(f'  High Severity: {summary[\"high_severity_issues\"]}')
        print(f'  Critical: {summary[\"critical_issues\"]}')
        print(f'  Reports Generated: {len(summary[\"reports_found\"])}')
        "
    
    - name: Upload security summary
      uses: actions/upload-artifact@v3
      with:
        name: security-summary
        path: security-summary.json
        retention-days: 90
    
    - name: Comment security summary on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          try {
            const summary = JSON.parse(fs.readFileSync('security-summary.json', 'utf8'));
            
            const comment = `
            ## 🔒 Security Scan Results
            
            **Scan Details:**
            - Timestamp: ${summary.scan_timestamp}
            - Commit: ${summary.commit.substring(0, 7)}
            - Branch: ${summary.branch}
            
            **Summary:**
            - 🔍 Total Issues: ${summary.total_issues}
            - ⚠️ High Severity: ${summary.high_severity_issues}
            - 🚨 Critical: ${summary.critical_issues}
            - 📊 Reports Generated: ${summary.reports_found.length}
            
            **Reports:** ${summary.reports_found.join(', ')}
            
            ${summary.critical_issues > 0 ? '🚨 **Critical issues found! Please review before merging.**' : ''}
            ${summary.high_severity_issues > 5 ? '⚠️ **Multiple high-severity issues detected.**' : ''}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not post security summary comment:', error);
          }